{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUmZS2WJeMXTWHZ1kwrWVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashifletslearn/Day-12-30/blob/main/Day_12_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hello i am Kashif khan let's learn together\n",
        "\n",
        "1.   Github   : https://github.com/Kashifletslearn/Day-12-30\n",
        "2.   Linkedin : https://www.linkedin.com/in/kashifkhank/\n",
        "3.   Gmail    : kashifdocument11@gmail.com\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "__Jx8D8lKlcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For suggestions and improvement Email me\n"
      ],
      "metadata": {
        "id": "NSCSBEllfsLt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abfzTPI9ZfW1"
      },
      "source": [
        "# <u> Problem 1</u>\n",
        "\n",
        "## You are given a sentence : <code>\"I have been walking and running and dancing and smiling and laughing all my life, yet it all seems pointless.\"</code>\n",
        "\n",
        "## You are required to extract all those words from this sentence in a list which ends with <code>ing</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iyfDeUBZtWy"
      },
      "source": [
        "my_sentence = \"I have been walking and running and dancing and smiling and laughing all my life, yet it all seems pointless.\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXK6kbsNZ_Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29463f3e-22e5-4905-abd0-663d1fbf26d3"
      },
      "source": [
        "# Using list comprehension\n",
        "\n",
        "all_words_in_sentence = my_sentence.split(' ')\n",
        "\n",
        "\n",
        "# Words ending with ing\n",
        "words_ending_with_ing =  [word for word in all_words_in_sentence if word[-3:] == 'ing']\n",
        "\n",
        "\n",
        "print(words_ending_with_ing)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walking', 'running', 'dancing', 'smiling', 'laughing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXCwNxAzaTEJ"
      },
      "source": [
        "# <u> Problem 2</u>\n",
        "\n",
        "#### Natural Language Processing or NLP is one of the most promising fields in Machine Learning. Most of the times in NLP we deal with the textual data (a bunch of strings). Sometimes when we are processing the text, it is a common practice to get rid of some set of stop words from our original text. By default stop words are very common words used in English language such as and, or, punctuations etc.\n",
        "\n",
        "#### In this exercise, you are provided with a default set of stop words and you need to add some extra set of custom words and remove these words from the given sentence and obtain the sentence without the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXHGkia-avfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38444109-4159-440c-98dc-1eaaf6b0d77f"
      },
      "source": [
        "sentence = 'Hello, good morning folks! Today we will announce the half yearly performance results of the company. Due to the ongoing COVID-19 pandemic, our profits have declined by 60% as compared to the last year'\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, good morning folks! Today we will announce the half yearly performance results of the company. Due to the ongoing COVID-19 pandemic, our profits have declined by 60% as compared to the last year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05HVN3G8ayeJ"
      },
      "source": [
        "# Default set of stop words\n",
        "stop_words = {\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
        "              \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n",
        "              \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
        "              \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n",
        "              \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n",
        "              \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n",
        "              \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n",
        "              \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
        "              \"don\", \"should\", \"now\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmmyFKooa38P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5076dc93-a56b-4e7c-b199-f5de24f7b600"
      },
      "source": [
        "# Update the set of stop words by adding the custom stop words\n",
        "custom_stop_words = [\"hello\",\"good\",\"morning\",\"half\",\"year\"]\n",
        "\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "print(stop_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'t', 'these', 'about', 'does', 'of', 'but', 's', 'yours', 'he', 'that', 'through', 'because', 'had', 'is', 'ourselves', 'from', 'only', 'you', 'don', 'why', 'down', 'now', 'she', 'while', 'was', 'when', 'nor', 'year', 'me', 'be', 'here', 'into', 'our', 'its', 'more', 'too', 'myself', 'who', 'yourselves', 'against', 'so', 'doing', 'until', 'any', 'this', 'further', 'we', 'theirs', 'most', 'own', 'by', 'during', 'should', 'good', 'what', 'their', 'out', 'on', 'and', 'her', 'both', 'were', 'there', 'those', 'if', 'above', 'all', 'below', 'in', 'i', 'they', 'how', 'herself', 'yourself', 'whom', 'before', 'which', 'other', 'am', 'under', 'ours', 'hers', 'them', 'been', 'did', 'same', 'with', 'once', 'themselves', 'him', 'himself', 'no', 'again', 'over', 'as', 'an', 'being', 'some', 'will', 'his', 'have', 'a', 'just', 'it', 'at', 'itself', 'where', 'has', 'are', 'for', 'do', 'can', 'hello', 'morning', 'having', 'very', 'the', 'between', 'your', 'few', 'off', 'after', 'not', 'such', 'than', 'or', 'each', 'up', 'half', 'then', 'my', 'to'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlqG037ya_dz"
      },
      "source": [
        "# spliting sentence by space\n",
        "words_in_sentence = sentence.split(' ')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu-YASV8a_Oc"
      },
      "source": [
        "# Using list comprehension to remove the set of updated stop words from the list of words\n",
        "words_to_keep = [word for word in words_in_sentence if word not in stop_words]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wUMd7U_bMWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9464c86-164b-4c3e-fa0c-378b869b686c"
      },
      "source": [
        "# Finally using the join() method\n",
        "modified_sentence = \" \".join(words_to_keep)\n",
        "\n",
        "print(modified_sentence)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, folks! Today announce yearly performance results company. Due ongoing COVID-19 pandemic, profits declined 60% compared last\n"
          ]
        }
      ]
    }
  ]
}